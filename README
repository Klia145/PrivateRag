# Intelligent Document Q&A System (RAG)

## Overview

The Intelligent Document Q&A System is a retrieval-augmented generation (RAG) solution designed for local knowledge-based question answering. It provides a user-friendly interface for uploading, processing, indexing, and querying textual documents, enabling quick and precise answers from your local document database.

## Features

- **Document Upload & Processing**: Supports uploading `.txt` documents, automatically chunked and indexed for efficient retrieval.
- **Retrieval-Augmented Generation (RAG)**: Generate accurate answers based on retrieved context from indexed documents.
- **Interactive GUI**: Intuitive Tkinter-based graphical interface for ease of use.

## Components

The system consists of three main components:

1. **Document Processor** (`buildTheKnowledge.py`):
   - Processes and chunks documents
   - Generates embeddings using SentenceTransformers
   - Indexes embeddings using FAISS

2. **Retrieval & Generation System**:
   - Retrieves relevant document chunks from FAISS
   - Generates responses using local SentenceTransformer embeddings
   - Communicates with local Ollama API for text generation

3. **User Interface (Tkinter GUI)**:
   - Facilitates file uploads and management
   - Provides an intuitive Q&A interface
   - Displays processing and query generation status clearly

## Project Structure

```
project/
├── DateBase                           # Directory for uploaded documents
├── ThemessageDatebase                 # Directory for processed data and indices
│   ├── chunks.txt                     # Document chunks
│   └── knowledge.index                # FAISS index
├── buildTheKnowledge.py               # Document processing script
├── BuildTheRAG.py                     # Retrieval & generation logic
└── main.py                            # Main application script (Tkinter GUI)
```

## Installation

### Prerequisites

- Python 3.10 or newer
- FAISS
- SentenceTransformers
- Ollama API (local inference)

Install required Python packages using pip:

```bash
pip install faiss-cpu sentence-transformers unstructured
```

Ensure you have a local Ollama server running:

```bash
ollama serve
```

### Running the Application

```bash
python main.py
```

- Launch the GUI application.
- Upload your `.txt` documents.
- Use the interactive QA interface to ask questions.

## Technical Details

### Components

- **FAISS**: Efficient vector similarity search for retrieving relevant document chunks.
- **SentenceTransformers**: Encodes textual data into embeddings.
- **Tkinter GUI**: Intuitive interface for document management and interactive Q&A.
- **Ollama API**: Provides advanced language generation capabilities.

## Usage

### Document Upload
- Click the **"选择并上传TXT文档"** button.
- Choose a `.txt` file to upload.
- The system will automatically process and index the document.

### Asking Questions
- Enter your question in the provided input box.
- Click **"提交问题"** to retrieve context-based answers.

### Troubleshooting
- **Upload Errors**: Check console logs for detailed error messages.
- **Generation Errors**: Ensure Ollama server is running and accessible.

## Technical Notes

- FAISS index and embedding models must be stored locally.
- Arbitrary Python execution is restricted for security.

## Caution

- Always backup important data.
- Ensure proper setup and configuration before deployment.

## Contributing

- Contributions and feedback are welcome! Please open issues or submit PRs.

## License

This project is licensed under the MIT License.

